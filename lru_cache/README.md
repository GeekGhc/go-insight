# lru cache 
lru cache 作为常见的缓存淘汰算法，是指最近最少使用策略的写法，是根据数据的历史访问记录来进行淘汰数据

核心思想是"如果数据最近被访问，那么将来被访问的几率也会更高"，他主要解决的就是热点数据访问的场景

其基本特性如下：
- 线程安全
- 支持被动触发过期时间
- 支持key和value任意类型
- 基于双向链表和hash表实现

使用双向链表是利用链表本身的插入、删除、移动的效率非常高。所以可以高效的维护热点数据的key
而lru cache 通常也会有大量的以上操作,在双向链表场景下，以上的时间复杂度也都是O(1)

而在数据的查询上，链表表现的并不高效，因此引入Hash表来存储每个key对应的指针，这样可以避免每次查询都要变遍历整个链表

## 基本思路
首先会使用双向链表将所有元素连接起来，当一个位置被访问后，将通过调整链表的指向

将该位置调整到链表的**头部**，而新加入的cache节点也会直接加到链表头部

这样多次的访问操作之后，最近被访问的数据，就会一直被向链表的头部移动。

而没有访问的则是不断向链表尾部移动，而这些节点数据表示的就是最近最少使用的cache

当缓存容量达到上限时，链表的尾部就是最少被访问的数据，我们只需要删除链表最后的cache节点数据便可以添加新的cache


